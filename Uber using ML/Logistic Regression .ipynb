{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please be informed that the uber credits that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey babu we would like to take a closer look a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey roshan were grateful to have such uberstar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey rakesh could you please share the date and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey ananth we understand this can be upsetting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category\n",
       "0  please be informed that the uber credits that ...         1\n",
       "1  hey babu we would like to take a closer look a...         1\n",
       "2  hey roshan were grateful to have such uberstar...         1\n",
       "3  hey rakesh could you please share the date and...         1\n",
       "4  hey ananth we understand this can be upsetting...         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Text\n",
    "\n",
    "data = pd.read_csv(\"Uber_Category_500.csv\",encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please be informed that the uber credits that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>please be informed that the uber credits that ...</td>\n",
       "      <td>[please, be, informed, that, the, uber, credit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey babu we would like to take a closer look a...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey babu we would like to take a closer look a...</td>\n",
       "      <td>[hey, babu, we, would, like, to, take, a, clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey roshan were grateful to have such uberstar...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey roshan were grateful to have such uberstar...</td>\n",
       "      <td>[hey, roshan, were, grateful, to, have, such, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey rakesh could you please share the date and...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey rakesh could you please share the date and...</td>\n",
       "      <td>[hey, rakesh, could, you, please, share, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey ananth we understand this can be upsetting...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey ananth we understand this can be upsetting...</td>\n",
       "      <td>[hey, ananth, we, understand, this, can, be, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category  \\\n",
       "0  please be informed that the uber credits that ...         1   \n",
       "1  hey babu we would like to take a closer look a...         1   \n",
       "2  hey roshan were grateful to have such uberstar...         1   \n",
       "3  hey rakesh could you please share the date and...         1   \n",
       "4  hey ananth we understand this can be upsetting...         0   \n",
       "\n",
       "                                               clean  \\\n",
       "0  please be informed that the uber credits that ...   \n",
       "1  hey babu we would like to take a closer look a...   \n",
       "2  hey roshan were grateful to have such uberstar...   \n",
       "3  hey rakesh could you please share the date and...   \n",
       "4  hey ananth we understand this can be upsetting...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [please, be, informed, that, the, uber, credit...  \n",
       "1  [hey, babu, we, would, like, to, take, a, clos...  \n",
       "2  [hey, roshan, were, grateful, to, have, such, ...  \n",
       "3  [hey, rakesh, could, you, please, share, the, ...  \n",
       "4  [hey, ananth, we, understand, this, can, be, u...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Text\n",
    "\n",
    "df_clean = data\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df_clean['clean'] = df_clean['Tweets'].astype('str') \n",
    "df_clean.dtypes\n",
    "\n",
    "df_clean[\"tokens\"] = df_clean[\"clean\"].apply(tokenizer.tokenize)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Word2Vec\n",
    "\n",
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107022823, 941840000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# WORD2VEC()\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer, important for a parameter of the model\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "#BUILD_VOCAB()\n",
    "\n",
    "w2v_model.build_vocab(df_clean[\"tokens\"], progress_per=1000)\n",
    "\n",
    "\n",
    "#TRAIN()\n",
    "\n",
    "w2v_model.train(df_clean[\"tokens\"], total_examples=w2v_model.corpus_count, epochs=10000, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('via', 0.3977193236351013),\n",
       " ('help', 0.3931013345718384),\n",
       " ('section', 0.3802177309989929),\n",
       " ('direct', 0.347443163394928),\n",
       " ('app', 0.3397883176803589),\n",
       " ('message', 0.3341812193393707),\n",
       " ('your', 0.3321651518344879),\n",
       " ('us', 0.32056373357772827),\n",
       " ('number', 0.28352048993110657),\n",
       " ('email', 0.2777360677719116)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words similar to thanks\n",
    "w2v_model.wv.most_similar(positive=[\"thanks\"])\n",
    "\n",
    "#Words similar to please\n",
    "w2v_model.wv.most_similar(positive=[\"please\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First defining the X (input), and the y (output)\n",
    "\n",
    "y = data['Category'].values\n",
    "X = np.array(df_clean[\"tokens\"])\n",
    "\n",
    "#And here is the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming & Fitting Vectorizer to Train Data\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transforming Vectorizer to Test Data\n",
    "\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 391\n"
     ]
    }
   ],
   "source": [
    "# Getting Number of Features from the Vectorizer \n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Mean Cross-Validation Accuracy\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Mean Cross-Validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.931\n",
      "Testing set score: 0.927\n"
     ]
    }
   ],
   "source": [
    "# Fitting Train Data with Logistic Regression Algorithm\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 45  42]\n",
      " [  2 511]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Sentiments with the Test Data & Creating the Confusion Matrix\n",
    "\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
