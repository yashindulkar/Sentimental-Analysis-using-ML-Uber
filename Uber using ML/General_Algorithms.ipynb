{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Text\n",
    "\n",
    "data = pd.read_csv(\"Uber_Category_3000.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi we understand this can be upsetting driver ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey savani weve fixed this for you and process...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey sanju for us to assist you better kindly h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we understand your concern nikhil we have made...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey vinay were sorry to hear about the trouble...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category\n",
       "0  hi we understand this can be upsetting driver ...         1\n",
       "1  hey savani weve fixed this for you and process...         1\n",
       "2  hey sanju for us to assist you better kindly h...         1\n",
       "3  we understand your concern nikhil we have made...         0\n",
       "4  hey vinay were sorry to hear about the trouble...         1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text\n",
    "\n",
    "df_clean = data\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df_clean['clean'] = df_clean['Tweets'].astype('str') \n",
    "df_clean.dtypes\n",
    "\n",
    "df_clean[\"tokens\"] = df_clean[\"clean\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi we understand this can be upsetting driver ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi we understand this can be upsetting driver ...</td>\n",
       "      <td>[hi, we, understand, this, can, be, upsetting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey savani weve fixed this for you and process...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey savani weve fixed this for you and process...</td>\n",
       "      <td>[hey, savani, weve, fixed, this, for, you, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey sanju for us to assist you better kindly h...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey sanju for us to assist you better kindly h...</td>\n",
       "      <td>[hey, sanju, for, us, to, assist, you, better,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we understand your concern nikhil we have made...</td>\n",
       "      <td>0</td>\n",
       "      <td>we understand your concern nikhil we have made...</td>\n",
       "      <td>[we, understand, your, concern, nikhil, we, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey vinay were sorry to hear about the trouble...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey vinay were sorry to hear about the trouble...</td>\n",
       "      <td>[hey, vinay, were, sorry, to, hear, about, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category  \\\n",
       "0  hi we understand this can be upsetting driver ...         1   \n",
       "1  hey savani weve fixed this for you and process...         1   \n",
       "2  hey sanju for us to assist you better kindly h...         1   \n",
       "3  we understand your concern nikhil we have made...         0   \n",
       "4  hey vinay were sorry to hear about the trouble...         1   \n",
       "\n",
       "                                               clean  \\\n",
       "0  hi we understand this can be upsetting driver ...   \n",
       "1  hey savani weve fixed this for you and process...   \n",
       "2  hey sanju for us to assist you better kindly h...   \n",
       "3  we understand your concern nikhil we have made...   \n",
       "4  hey vinay were sorry to hear about the trouble...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [hi, we, understand, this, can, be, upsetting,...  \n",
       "1  [hey, savani, weve, fixed, this, for, you, and...  \n",
       "2  [hey, sanju, for, us, to, assist, you, better,...  \n",
       "3  [we, understand, your, concern, nikhil, we, ha...  \n",
       "4  [hey, vinay, were, sorry, to, hear, about, the...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing \n",
    "\n",
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107028705, 941840000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# WORD2VEC()\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer, important for a parameter of the model\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "#BUILD_VOCAB()\n",
    "\n",
    "w2v_model.build_vocab(df_clean[\"tokens\"], progress_per=1000)\n",
    "\n",
    "\n",
    "#TRAIN()\n",
    "\n",
    "w2v_model.train(df_clean[\"tokens\"], total_examples=w2v_model.corpus_count, epochs=10000, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('via', 0.37331557273864746),\n",
       " ('message', 0.3613654673099518),\n",
       " ('direct', 0.34762924909591675),\n",
       " ('this', 0.3421033024787903),\n",
       " ('email', 0.32505300641059875),\n",
       " ('registered', 0.3240955173969269),\n",
       " ('help', 0.3181191682815552),\n",
       " ('can', 0.31372693181037903),\n",
       " ('number', 0.3121623396873474),\n",
       " ('also', 0.3105176091194153)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words similar to thanks\n",
    "w2v_model.wv.most_similar(positive=[\"understand\"])\n",
    "\n",
    "#Words similar to please\n",
    "w2v_model.wv.most_similar(positive=[\"please\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First defining the X (input), and the y (output)\n",
    "\n",
    "y = data['Category'].values\n",
    "X = np.array(df_clean[\"tokens\"])\n",
    "\n",
    "#And here is the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function <lambda> at 0x00000147A1C4F948>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=10, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 391\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestClassifier(), X_train, y_train, cv=5)\n",
    "print(\"Mean Cross-Validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.931\n",
      "Testing set score: 0.927\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 45  42]\n",
      " [  2 511]]\n"
     ]
    }
   ],
   "source": [
    "pred_logreg = logreg.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.877\n",
      "Testing set score: 0.878\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nb.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(nb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 14  73]\n",
      " [  0 513]]\n"
     ]
    }
   ],
   "source": [
    "pred_nb = nb.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_nb)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Testing set score: 0.963\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, bootstrap= True, max_features = 'sqrt')\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 68  19]\n",
      " [  3 510]]\n"
     ]
    }
   ],
   "source": [
    "pred_rf = rf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_rf)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
